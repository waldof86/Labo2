{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejemplo Trading",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Argentan/DMA_LAB2/blob/master/tutoriales/08_Ejemplo_RNN_Trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_l9hRpryNmO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Normalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taJBCFBkyfwO"
      },
      "source": [
        "# Leer un Ticket, frecuencia de la observación = 3 Minutos\n",
        "intrad = pd.read_csv('https://github.com/Argentan/DMA_LAB2/blob/master/data/AAPL.csv.gz?raw=true', compression='gzip', parse_dates=[0], index_col=[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6al_m5aFzFWp"
      },
      "source": [
        "intrad.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPG91qugabYB",
        "outputId": "4ad5b143-7ca0-44a0-b2b2-c6d8e587cc58"
      },
      "source": [
        "intrad.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(337010, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKhJ6XTs35ew"
      },
      "source": [
        "# Define Función para Agrupar datos por Hora (H), Dia (D), Semana (W) - Ver al final más opciones\n",
        "\n",
        "def agrupar_temporalmente(dataset, frecuencia = 'D'):\n",
        "  df = pd.DataFrame()\n",
        "  df['Open']   = intrad.Open.resample(frecuencia).first().dropna()\n",
        "  df['High']   = intrad.High.resample(frecuencia).max().dropna()\n",
        "  df['Low']    = intrad.Low.resample(frecuencia).min().dropna()\n",
        "  df['Close']  = intrad.Close.resample(frecuencia).last().dropna()\n",
        "  df['Volume'] = intrad.Volume.resample(frecuencia).sum().dropna()\n",
        "  df['WAP']    = (intrad['WAP'] * intrad['Volume']).resample(frecuencia).sum() / intrad.resample(frecuencia)['Volume'].sum().dropna()\n",
        "  df['Count']  = intrad.Count.resample(frecuencia).sum().dropna()\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cJ0abpVKevS"
      },
      "source": [
        "# Agrupa por día\n",
        "diario = agrupar_temporalmente(intrad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V411-OXnKlSd"
      },
      "source": [
        "diario.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zvyIN_lOIKN"
      },
      "source": [
        "# Graficar\n",
        "fig = go.Figure(data=[go.Candlestick(x=diario.index,\n",
        "                               open=diario.Open, \n",
        "                               high=diario.High,\n",
        "                               low=diario.Low, \n",
        "                               close=diario.Close)])\n",
        "fig.update_layout(autosize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0S82TrJQZx2"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcXRlaAIj3Hs"
      },
      "source": [
        "Ver tf.keras.utils.normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pw82MDkXFzr"
      },
      "source": [
        "# Creamos una función para normalizar y armar train y test por ventanas de tiempo\n",
        "\n",
        "def multivariate_data(dataset, target_col, train_perc, history_size, future_target, step = 1):\n",
        "  \n",
        "  train_split = int(round(dataset.shape[0] * train_perc ,0))\n",
        "  \n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "  # Crear listas vacias y separar el Target\n",
        "  x_train, y_train, x_valid, y_valid  = [], [], [], []\n",
        "  target = dataset[:, target_col]\n",
        "\n",
        "  # Armar las observaciones de Train\n",
        "  for i in range(history_size, train_split):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    x_train.append(dataset[indices])\n",
        "\n",
        "    y_train.append(target[i : i + future_target])\n",
        "\n",
        "  # Armar las observaciones de Valid\n",
        "  start_index = train_split + history_size\n",
        "  end_index = len(dataset) - future_target\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    x_valid.append(dataset[indices])\n",
        "\n",
        "    y_valid.append(target[i : i + future_target])\n",
        "\n",
        "  return np.array(x_train), np.array(y_train), np.array(x_valid), np.array(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oATGXQTLOEHA"
      },
      "source": [
        "# Definimos los parámetos para armar la base\n",
        "\n",
        "train_perc = 0.8    # Porcentaje de obesrvaciones que se usan para Train (el resto es Valid) \n",
        "history_size = 10   # Cuantas obesrvaciones pasadas mirar\n",
        "future_target = 1   # Cuantas observaciones en el futuro tiene que predecir\n",
        "step = 1            # Pasos que da la ventana por cada observación\n",
        "target_col = 3      # Columna que se va a usar de target\n",
        "\n",
        "x_train, y_train, x_val, y_val = multivariate_data(diario, target_col, train_perc, history_size, future_target, step)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4-WZJBebc-c"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgeCAy517RWX"
      },
      "source": [
        "# Armamos el Modelo\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape = x_train.shape[-2:]))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compilamos el Modelo\n",
        "model.compile(optimizer= 'adam', loss= 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYAmR0Ht7dHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c155a01e-d151-47df-c925-3ba4e48d29a9"
      },
      "source": [
        "# Entrenamos\n",
        "model.fit(x_train, y_train, batch_size= 8, epochs = 10, \n",
        "          steps_per_epoch = 500, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 3.8305e-04 - val_loss: 0.0019\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 7.0769e-05 - val_loss: 0.0021\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 6.7525e-05 - val_loss: 0.0013\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 5.8713e-05 - val_loss: 4.7654e-04\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 5.1547e-05 - val_loss: 3.3721e-04\n",
            "Epoch 6/10\n",
            " 43/500 [=>............................] - ETA: 1s - loss: 6.7553e-05WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5000 batches). You may need to use the repeat() function when building your dataset.\n",
            " 50/500 [==>...........................] - 0s 6ms/step - loss: 7.0726e-05 - val_loss: 2.5175e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc8b391e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31WZg-w94xUp"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "# Notas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBV93bBr4wpQ"
      },
      "source": [
        "# Opciones de resample\n",
        "# B         business day frequency\n",
        "# C         custom business day frequency (experimental)\n",
        "# D         calendar day frequency\n",
        "# W         weekly frequency\n",
        "# M         month end frequency\n",
        "# SM        semi-month end frequency (15th and end of month)\n",
        "# BM        business month end frequency\n",
        "# CBM       custom business month end frequency\n",
        "# MS        month start frequency\n",
        "# SMS       semi-month start frequency (1st and 15th)\n",
        "# BMS       business month start frequency\n",
        "# CBMS      custom business month start frequency\n",
        "# Q         quarter end frequency\n",
        "# BQ        business quarter endfrequency\n",
        "# QS        quarter start frequency\n",
        "# BQS       business quarter start frequency\n",
        "# A         year end frequency\n",
        "# BA, BY    business year end frequency\n",
        "# AS, YS    year start frequency\n",
        "# BAS, BYS  business year start frequency\n",
        "# BH        business hour frequency\n",
        "# H         hourly frequency\n",
        "# T, min    minutely frequency\n",
        "# S         secondly frequency\n",
        "# L, ms     milliseconds\n",
        "# U, us     microseconds\n",
        "# N         nanoseconds"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}